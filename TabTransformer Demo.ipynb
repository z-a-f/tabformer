{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62705e7c-2592-4528-8b97-87c128601005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = '''\n",
    "page_protocol,page_host,api_protocol,api_host,api_path,api_method,psm,scope,field_name,field_path,field_sample,data_type_name\n",
    "https,market-au.example.com,https,market-au.example.com,/api/v1/product/prohibited/words/check,post,oec.product.product_api,query,browser_language,browser_language,en-US,Language\n",
    "https,market-au.example.com,https,market-au.example.com,/api/v1/product/prohibited/words/check,post,oec.product.product_api,query,browser_language,browser_language,en-US,Language\n",
    "https,market-au.example.com,https,market-au.example.com,/api/v1/product/prohibited/words/check,post,oec.product.product_api,query,browser_language,browser_language,en-US,Language\n",
    "https,market-au.example.com,https,open-api.example.com,/v0/oauth/check_qr,get,abcd.openapi.gateway,query,token,token,abcd_aueast3,Account Setting\n",
    "https,market-au.example.com,https,open-api.example.com,/v0/oauth/check_qr,get,abcd.openapi.gateway,query,token,token,wxyz_aueast3,Account Setting\n",
    "https,market-au.example.com,https,market-au.example.com,/api/v1/product/list/seller/warehouses,get,oec.product.product_api,query,browser_version,browser_version,5.0%20%28Windows%20NT%2010.0%3B%20Win64%3B%20x64%29%20AppleWebKit%2F537.36%20%28KHTML%2C%20like%20Gecko%29%20Chrome%2F120.0.0.0%20Safari%2F537.36,User Agent\n",
    "https,market-au.example.com,https,market-au.example.com,/api/v1/seller/holiday_mode/list,get,oec.seller.profile_api,query,locale,locale,en,Language\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff3d2ee-0502-4438-8e3b-3b09a59f1b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   page_protocol   7 non-null      object\n",
      " 1   page_host       7 non-null      object\n",
      " 2   api_protocol    7 non-null      object\n",
      " 3   api_host        7 non-null      object\n",
      " 4   api_path        7 non-null      object\n",
      " 5   api_method      7 non-null      object\n",
      " 6   psm             7 non-null      object\n",
      " 7   scope           7 non-null      object\n",
      " 8   field_name      7 non-null      object\n",
      " 9   field_path      7 non-null      object\n",
      " 10  field_sample    7 non-null      object\n",
      " 11  data_type_name  7 non-null      object\n",
      "dtypes: object(12)\n",
      "memory usage: 804.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data = pd.read_csv(StringIO(data_csv))\n",
    "target_column = 'data_type_name'\n",
    "feature_columns = data.columns[data.columns != target_column]\n",
    "target_columns = data.columns[data.columns == target_column]  # Keep this to maintain the DataFrame\n",
    "\n",
    "if len(target_columns) > 1:\n",
    "    raise ValueError(f'Multilabel not implemented yet')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640285f1-5dfe-4121-9b08-4b46de8c56a2",
   "metadata": {},
   "source": [
    "# Step 1. Collect some info\n",
    "\n",
    "TODO: Remove NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7c4c45-12da-4f9b-a25f-beffafdace86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the statistics for categorical and numerical columns in X\n",
    "# categorical = data[feature_columns].select_dtypes(['category', 'object']).columns\n",
    "categorical = data.select_dtypes(['category', 'object']).columns\n",
    "numerical = data.columns[~data.columns.isin(categorical)]\n",
    "data[categorical] = data[categorical].astype('category')\n",
    "\n",
    "target_column_dtype = data[target_columns[0]].dtype  # Only a single target for now\n",
    "if target_column_dtype in ('object', 'category'):\n",
    "    # Classification\n",
    "    output_dimensions = len(target_column_dtype.categories)\n",
    "    if output_dimensions == 2:\n",
    "        output_dimensions = 1  # Binary classification can be done with a single output\n",
    "else:\n",
    "    # Regression\n",
    "    output_dimensions = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c5e73-aa19-47f6-b1b1-0442b1ce98ca",
   "metadata": {},
   "source": [
    "# Step 2. Convert the data to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7de54f-b99b-4722-9512-785a529d2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def to_feature_target(data, feature_columns, target_columns):\n",
    "    '''\n",
    "    Args:\n",
    "        data: Pandas DataFrame\n",
    "        feature_columns: Columns that are representation of features\n",
    "        target_columns: Column names that are tepresentation of prediction targets\n",
    "    '''\n",
    "    Xy = data.copy()\n",
    "    Xy[categorical] = Xy[categorical].apply(lambda column: column.cat.codes)\n",
    "    \n",
    "    X = Xy[feature_columns]\n",
    "    y = Xy[target_columns]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def to_cat_num(data, categorical, numerical):\n",
    "    '''\n",
    "    Args:\n",
    "        data: Pandas DataFrame\n",
    "        categorical: Columns that are categorical\n",
    "        numerical: Columns that are numerical\n",
    "    '''\n",
    "    data_cat = data[categorical.intersection(feature_columns)]\n",
    "    data_num = data[numerical.intersection(feature_columns)]\n",
    "    return data_cat, data_num\n",
    "\n",
    "def to_tensor(X_cat, X_num, y=None):\n",
    "    X_cat_tensor = torch.tensor(X_cat.values, dtype=torch.long)\n",
    "    X_num_tensor = torch.tensor(X_num.values, dtype=torch.float32)\n",
    "\n",
    "    if y is not None:\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "    \n",
    "        if y_tensor.ndim == 2 and y_tensor.shape[1] == 1:\n",
    "            y_tensor = y_tensor.flatten()\n",
    "        if y_tensor.ndim != 1:\n",
    "            raise ValueError(f'Multitarget is not supported yet')\n",
    "    \n",
    "        return X_cat_tensor, X_num_tensor, y_tensor\n",
    "    else:\n",
    "        return X_cat_tensor, X_num_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e374b5e-e34c-4cf8-82d4-60a7e472827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = to_feature_target(data, feature_columns, target_columns)\n",
    "X_cat, X_num = to_cat_num(X, categorical, numerical)\n",
    "X_cat_tensor, X_num_tensor, y_tensor = to_tensor(X_cat, X_num, y)\n",
    "\n",
    "# Need the number of categories in each categorical column for the embedding layers\n",
    "X_num_categorical = [len(X[column].unique()) for column in categorical if column not in target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d4606-9f09-43ea-9814-bdf1e7d1df63",
   "metadata": {},
   "source": [
    "# Step 3. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e8a93e-a356-427c-b7ad-1d685137db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (category_embed): Embedding(30, 28)\n",
       "  (transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Attention(\n",
       "            (to_qkv): Linear(in_features=32, out_features=288, bias=False)\n",
       "            (to_out): Linear(in_features=96, out_features=32, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (1): GEGLU()\n",
       "              (2): Dropout(p=0.1, inplace=False)\n",
       "              (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=352, out_features=1408, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1408, out_features=704, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=704, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "# Hyperparameters from the original paper\n",
    "params = {\n",
    "    'dim': 32,\n",
    "    'depth': 6,\n",
    "    'heads': 6,\n",
    "    'attn_dropout': 0.1,\n",
    "    'ff_dropout': 0.1,\n",
    "    'mlp_hidden_mults': (4, 2),\n",
    "    'mlp_act': nn.ReLU(),  # Can be reused, as this is stateless\n",
    "    'use_shared_categ_embed': True,\n",
    "}\n",
    "\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories = X_num_categorical,\n",
    "    num_continuous = len(numerical),\n",
    "    dim_out = output_dimensions,\n",
    "    # continuous_mean_std = mean_std,\n",
    "    **params,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5593ab-260b-4815-a677-1c64c5f3c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number of parameters: 1642103\n",
      "Model size: 6.60 Mb\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Compute rough number of parameters\n",
    "num_parameters = 0\n",
    "for param in model.parameters():\n",
    "    num_parameters += param.numel()\n",
    "print(f'Model number of parameters: {num_parameters}')\n",
    "\n",
    "# Get the model size, as saved\n",
    "model_path = Path('/tmp/tab-transformer-temp.pt')\n",
    "torch.save(model.cpu().state_dict(), model_path)\n",
    "model_size_mb = model_path.stat().st_size / 1_000_000\n",
    "print(f'Model size: {model_size_mb:.2f} Mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52ec90-ae36-4b21-8a5d-bc0e03fc5373",
   "metadata": {},
   "source": [
    "# Step 4. Train the model\n",
    "\n",
    "**Note** We will be doing the supervised learning instead of unsupervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a39926c-61f1-426a-a0f6-5fda72519177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_inference(model, data, as_category=True):\n",
    "    '''Runs inference on a model'''\n",
    "    model_device = list(model.parameters())[0].device\n",
    "    # Get the tensor representaition -- note that target_columns could be empty\n",
    "    X, y = to_feature_target(data, feature_columns, [])\n",
    "    X_cat, X_num = to_cat_num(X, categorical, numerical)\n",
    "    X_cat_tensor, X_num_tensor = to_tensor(X_cat, X_num, None)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_cat_tensor = X_cat_tensor.to(model_device)\n",
    "        X_num_tensor = X_num_tensor.to(model_device)\n",
    "        y_hat = model(X_cat_tensor, X_num_tensor)\n",
    "\n",
    "        predictions = y_hat.argmax(-1)\n",
    "    if as_category:\n",
    "        # predictions = predictions.tolist()\n",
    "        return data[target_columns[0]].cat.categories[predictions.cpu()].tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14cf6ee-46fd-4c9a-9428-73a9e6594764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 1...\n",
      "  Predicted: \"User Agent\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 2...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 3...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 4...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 5...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"User Agent\"\n",
      "\n",
      "Sample 6...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Language\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random output\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "# model(X_cat_tensor, X_num_tensor)\n",
    "\n",
    "predictions = df_inference(model, data)\n",
    "for idx in range(len(data)):\n",
    "    print(f'Sample {idx}...')\n",
    "    print(f'  Predicted: \"{predictions[idx]}\"')\n",
    "    print(f'  Expected : \"{data.loc[idx, target_columns[0]]}\"')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f079ec2-7137-4d11-90e2-f2ecfabf9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # No batching -- dataset too small\n",
    "    X_cat_tensor = X_cat_tensor.to(device)\n",
    "    X_num_tensor = X_num_tensor.to(device)\n",
    "    y_tensor = y_tensor.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_hat = model(X_cat_tensor, X_num_tensor)\n",
    "    loss = criterion(y_hat, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e5fa5-6324-49ed-bce6-6a6de5741f3e",
   "metadata": {},
   "source": [
    "# Step 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31252cc0-5f95-444d-9908-ceaa1ebf42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 1...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 2...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 3...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 4...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 5...\n",
      "  Predicted: \"User Agent\"\n",
      "  Expected : \"User Agent\"\n",
      "\n",
      "Sample 6...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = df_inference(model, data)\n",
    "for idx in range(len(data)):\n",
    "    print(f'Sample {idx}...')\n",
    "    print(f'  Predicted: \"{predictions[idx]}\"')\n",
    "    print(f'  Expected : \"{data.loc[idx, target_columns[0]]}\"')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb52060-09c5-49e8-9a7a-949c4d2785a3",
   "metadata": {},
   "source": [
    "# Step 6. Save the trained model (Pure Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853e8018-f0e0-4ba2-aace-8845513d0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path('/tmp/tab-transformer-temp.pt')  # This is where the model will be saved to\n",
    "torch.save(model.cpu(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fa26e-6509-4e11-9172-1f0d5f9182c3",
   "metadata": {},
   "source": [
    "# Step 7. Load the model from the pretrained version (Pure Torch)\n",
    "\n",
    "This step will be done on target machine (inference server, edge device, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8699da03-32da-4e58-a5cb-b22fb190005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 1...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 2...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n",
      "Sample 3...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 4...\n",
      "  Predicted: \"Account Setting\"\n",
      "  Expected : \"Account Setting\"\n",
      "\n",
      "Sample 5...\n",
      "  Predicted: \"User Agent\"\n",
      "  Expected : \"User Agent\"\n",
      "\n",
      "Sample 6...\n",
      "  Predicted: \"Language\"\n",
      "  Expected : \"Language\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_model = torch.load(save_path)\n",
    "\n",
    "predictions = df_inference(inference_model, data)\n",
    "for idx in range(len(data)):\n",
    "    print(f'Sample {idx}...')\n",
    "    print(f'  Predicted: \"{predictions[idx]}\"')\n",
    "    print(f'  Expected : \"{data.loc[idx, target_columns[0]]}\"')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285dbca-26f1-47ed-8ee0-d92442f89ab0",
   "metadata": {},
   "source": [
    "# JIT PyTorch\n",
    "\n",
    "* This model does not support JIT scripting\n",
    "* This model does not support JIT tracing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
